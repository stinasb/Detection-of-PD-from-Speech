{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/stinasb/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import random\n",
    "\n",
    "from typing import List, Dict\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from speechbrain.lobes.models.Xvector import Xvector, Classifier\n",
    "from speechbrain.lobes.models import ECAPA_TDNN\n",
    "from speechbrain.utils.seed import seed_everything\n",
    " \n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "from speechbrain.nnet.pooling import AttentionPooling, StatisticsPooling\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "import librosa\n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"caching_allocator\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAttentionPooling(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.attn_pooling_w = torch.nn.Linear(input_dim, 1)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        attn_weights = self.attn_pooling_w(x).squeeze(-1).float()\n",
    "        \n",
    "        if mask is not None:\n",
    "            attn_weights[~mask] = float('-inf')\n",
    "        attn_weights = torch.nn.functional.softmax(attn_weights, dim=-1).unsqueeze(-1)\n",
    "        out = torch.sum(x*attn_weights, dim=1)\n",
    "        return out\n",
    "            \n",
    "\n",
    "class CustomStatisticsPooling(nn.Module):\n",
    "    def __init__(self, return_mean=True, return_std=True):\n",
    "        super().__init__()\n",
    "        self.eps = 1e-5\n",
    "        self.return_mean = return_mean\n",
    "        self.return_std = return_std\n",
    "        \n",
    "        if not (self.return_mean or self.return_std):\n",
    "            raise ValueError(\"Enable either mean and/or std for statistical pooling.\")\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        if mask is not None:\n",
    "            \n",
    "            \n",
    "            #mask = mask.unsqueeze(-1)  # Expand to match x's shape (batch_size, time_steps, features)\n",
    "            mask = mask.unsqueeze(-1).expand(-1, -1, x.size(-1))  \n",
    "            masked_x = x * mask.float()\n",
    "            valid_counts = mask.sum(dim=1).clamp(min=1) \n",
    "            \n",
    "            if self.return_mean:\n",
    "                mean = masked_x.sum(dim=1)/valid_counts\n",
    "\n",
    "            if self.return_std:\n",
    "                mean_expanded = mean.unsqueeze(1).expand(-1, x.size(1), -1)\n",
    "                \n",
    "                variance = ((masked_x-mean_expanded)**2*mask).sum(dim=1)/valid_counts\n",
    "                std = torch.sqrt(variance+self.eps)\n",
    "        else:\n",
    "            if self.return_mean:\n",
    "                mean = x.mean(dim=1)\n",
    "                \n",
    "            if self.return_std:\n",
    "                std = x.std(dim=1)\n",
    "                \n",
    "        if self.return_mean and self.return_std:\n",
    "            pooled_stats = torch.cat((mean, std), dim=1)\n",
    "        elif self.return_mean:\n",
    "            pooled_stats = mean\n",
    "        elif self.return_std:\n",
    "            pooled_stats = std\n",
    "            \n",
    "        return pooled_stats\n",
    "    \n",
    "    \n",
    "    \n",
    "class CustomXvector(Xvector):\n",
    "    def __init__(self, input_size, lin_neurons=512, activation=nn.LeakyReLU, device = 'cpu',tdnn_channels = [512, 512, 512, 512, 1500], use_stat_pool=False):\n",
    "        super().__init__(in_channels=input_size, lin_neurons=lin_neurons, activation=activation,tdnn_channels=tdnn_channels)\n",
    "        self.device = torch.device(device)\n",
    "        self.to(self.device)\n",
    "\n",
    "        self.out_channels = tdnn_channels[-1]\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        if use_stat_pool:\n",
    "            self.return_mean = True\n",
    "            self.return_std = True\n",
    "            self.blocks = nn.ModuleList([\n",
    "                *self.blocks[:-2],\n",
    "                CustomStatisticsPooling(),\n",
    "                nn.Linear(\n",
    "                    in_features= self.out_channels * (2 if self.return_mean and self.return_std else 1),  \n",
    "                    out_features=lin_neurons,\n",
    "                    bias=True,\n",
    "                )\n",
    "            ])\n",
    "        else:\n",
    "            self.blocks = nn.ModuleList([\n",
    "                *self.blocks[:-2],\n",
    "                CustomAttentionPooling(self.out_channels),\n",
    "                nn.Linear(\n",
    "                    in_features=self.out_channels,  # Adapt to the output size\n",
    "                    out_features=lin_neurons,\n",
    "                    bias=True,\n",
    "                )\n",
    "            ])\n",
    "        \n",
    "        \n",
    "        self.blocks.to(self.device)\n",
    "        \n",
    "        self.attention_layer = self.blocks[-2]\n",
    "        \n",
    "    def create_mask(self, lens, max_len=None):\n",
    "        if max_len is None:\n",
    "            max_len=lens.max()\n",
    "            \n",
    "        return torch.arange(max_len, device=lens.device)[None, :] < lens[:, None]\n",
    "    \n",
    "    def forward(self, x, lens=None):\n",
    "        if isinstance(x, list):\n",
    "            #for element in x:\n",
    "            x = [element.to(self.device) for element in x]\n",
    "        else:\n",
    "            x = x.to(self.device)\n",
    "            \n",
    "        mask = None\n",
    "        if lens is not None:\n",
    "            mask = self.create_mask(lens, x.size(1))\n",
    "        \n",
    "        for block in self.blocks[:-2]:\n",
    "            x = block(x)\n",
    "            \n",
    "        x = self.attention_layer(x, mask=mask)\n",
    "        x = self.blocks[-1](x)\n",
    "        return x #super().forward(x, lens)\n",
    "      \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, files, is_tv, labels: List[int], is_test= False, norm_feat = True, transform=None, target_transform=None):\n",
    "        super().__init__()\n",
    "        self.files = files\n",
    "        \n",
    "        self.labels = labels\n",
    "        self.is_test = is_test\n",
    "        self.is_tv = is_tv\n",
    "        self.norm_feat = norm_feat\n",
    "        \n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "                    \n",
    "        #data = pd.read_pickle(os.path.join(self.dir, self.files[idx])).to_numpy()  \n",
    "        \n",
    "        if self.is_tv: data = pd.read_pickle(self.files[idx]).to_numpy() \n",
    "        else:\n",
    "            #wav_file = pd.read_csv(self.files[idx])\n",
    "            samplerate, file = wavfile.read(self.files[idx])\n",
    "            feat = librosa.feature.melspectrogram(\n",
    "                y=file.astype(float), \n",
    "                sr=samplerate, \n",
    "                #n_fft=400,\n",
    "                #hop_length=160,\n",
    "                #win_length= 400,\n",
    "                #window=\"hamming\",\n",
    "                #center=False, \n",
    "                n_mels=80\n",
    "                )\n",
    "            #feat = librosa.feature.mfcc(y=file.astype(float), sr=samplerate)\n",
    "            log_mel = librosa.power_to_db(feat)\n",
    "            data = log_mel.transpose(1,0)\n",
    "            #data = feat.transpose(1,0)\n",
    "            \n",
    "        if self.norm_feat:\n",
    "            data = normalize(data, axis=0)\n",
    "        \n",
    "        return {'features' : data, 'label' : self.labels[idx]} \n",
    "    \n",
    "class WavTVDataset(Dataset):\n",
    "    def __init__(self, wav_dataset, tv_dataset):\n",
    "        super().__init__()\n",
    "        assert len(wav_dataset) == len(tv_dataset)\n",
    "        self.wav_dataset = wav_dataset\n",
    "        self.tv_dataset = tv_dataset\n",
    "        \n",
    "       \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.wav_dataset)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        wav_item = self.wav_dataset[idx]\n",
    "        tv_item = self.tv_dataset[idx]\n",
    "        \n",
    "        return {\n",
    "            'wav_features': wav_item['features'],\n",
    "            'tv_features': tv_item['features'],\n",
    "            'label': wav_item['label']\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_split_speaker_ids(speaker_ids,val_ratio : float=0.1):\n",
    "    \n",
    "    unique_speaker_ids = list(set(speaker_ids))\n",
    "    \n",
    "    unique_speaker_ids.sort()\n",
    "    random.shuffle(unique_speaker_ids)\n",
    "    \n",
    "    train_speaker_ids, val_speaker_ids = train_test_split(\n",
    "        unique_speaker_ids, test_size=val_ratio, random_state=42\n",
    "        )\n",
    "    \n",
    "    return train_speaker_ids, val_speaker_ids\n",
    "\n",
    "def split_dataset(samples, labels, train_speaker_ids, speaker_ids):\n",
    "        \n",
    "    t_paths, t_labels, v_paths, v_labels = [], [], [], []\n",
    "    \n",
    "    for path, label, speaker_id in zip(samples, labels, speaker_ids):\n",
    "        if speaker_id in train_speaker_ids:\n",
    "            t_paths.append(path)\n",
    "            t_labels.append(label)\n",
    "        else:\n",
    "            v_paths.append(path)\n",
    "            v_labels.append(label)\n",
    "   \n",
    "    \n",
    "    return t_paths, t_labels, v_paths, v_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(file_path):\n",
    "    return os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "\n",
    "def organize_data_in_folders(ds_type, fold):\n",
    "    target_dir = f\"/home/stinasb/SSL4PR/TV_train_test/Fold{fold}/{ds_type}/\"\n",
    "\n",
    "    original_dir = f\"/home/stinasb/SSL4PR/pcgita_splits/TRAIN_TEST_{fold}/{ds_type}.csv\"\n",
    "\n",
    "    file = pd.read_csv(original_dir)\n",
    "    \n",
    "    audio_path = list(file['audio_path'])\n",
    "\n",
    "    origin_id = list(file['original_id'])\n",
    "    speaker_ids = list(file['speaker_id'])\n",
    "    \n",
    "    dirname = '/home/stinasb/SSL4PR/TVs_copy_test/'\n",
    "\n",
    "    labels = []\n",
    "    filelist = []\n",
    "    origin_ids = []\n",
    "    speaker_id = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(dirname):\n",
    "        if os.path.basename(root) in {'hc', 'pd', 'HC', 'PD'}:\n",
    "            group = os.path.basename(root)\n",
    "            for file in files:\n",
    "                filename, extension = os.path.splitext(file)\n",
    "                if filename in origin_id:\n",
    "                    \n",
    "                    filelist.append(os.path.join(root, file))\n",
    "                    \n",
    "                    \n",
    "    \n",
    "    wav_files_sorted = sorted(audio_path, key=get_filename)\n",
    "    pkl_files_sorted = sorted(filelist, key=get_filename)\n",
    "    \n",
    "    for element in pkl_files_sorted:\n",
    "        filename = os.path.basename(element)\n",
    "        spk_id, extension = os.path.splitext(filename)\n",
    "        speaker_id.append(spk_id.split(\"_\")[0])\n",
    "        \n",
    "        group = os.path.basename(os.path.dirname(element))\n",
    "        if group == 'hc' or group == 'HC':\n",
    "            labels.append(0)\n",
    "        elif group == 'pd' or group == 'PD':\n",
    "            labels.append(1)\n",
    "                        \n",
    "        \n",
    "    file_dict = {'sample_tv': pkl_files_sorted, 'sample_wav': wav_files_sorted , 'labels': labels, 'speaker_id': speaker_id}\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(file_dict)\n",
    "    df.to_csv(target_dir + f\"{ds_type}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, input_size, lin_neurons, xvec, lin_blocks = 1, classifier_out_neurons = 2, device=\"cpu\"):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        \n",
    "        # Initialize the CustomXvector model\n",
    "        self.device = device\n",
    "        self.xvector = xvec.to(device)\n",
    "        # Initialize the Classifier model\n",
    "       \n",
    "        self.classifier = None\n",
    "        self.classifier_out_neurons = classifier_out_neurons\n",
    "        self.device = device\n",
    "        self.lin_blocks = lin_blocks\n",
    "        \n",
    "    def forward(self, x, lens=None):\n",
    "        # Forward pass through the x-vector model\n",
    "        xvector_output = self.xvector(x, lens)\n",
    "        \n",
    "        if self.classifier is None:\n",
    "            self.classifier = Classifier(\n",
    "                input_shape=xvector_output.shape,\n",
    "                out_neurons=self.classifier_out_neurons,\n",
    "                lin_blocks=self.lin_blocks,\n",
    "            ).to(self.device)\n",
    "            \n",
    "        # Forward pass through the classifier\n",
    "        classifier_output = self.classifier(xvector_output)\n",
    "        \n",
    "        return classifier_output\n",
    "\n",
    "class WavTVCombinedModel(nn.Module):\n",
    "    def __init__(self, wav_xvector, tv_xvector, mlp_hidden=256, num_classes=2, device='cpu', lin_blocks=2):\n",
    "        super(WavTVCombinedModel, self).__init__()\n",
    "        \n",
    "        self.wav_xvector = wav_xvector.to(device)\n",
    "        self.tv_xvector = tv_xvector.to(device)\n",
    "        #self.mlp_hidden = mlp_hidden\n",
    "        \n",
    "        #self.input_dim = self.wav_xvector.blocks[-1].out_features + self.tv_xvector.blocks[-1].out_features \n",
    "        \n",
    "        self.classifier = None\n",
    "        self.classifier_out_neurons = num_classes\n",
    "        self.device = device\n",
    "        self.lin_neurons = mlp_hidden\n",
    "        self.lin_blocks = lin_blocks\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, wav_input, tv_input, wav_lens=None, tv_lens=None):\n",
    "        \n",
    "        xvec_wav = self.wav_xvector(wav_input.float(), wav_lens)\n",
    "        xvec_tv = self.tv_xvector(tv_input.float(), tv_lens)\n",
    "        \n",
    "    \n",
    "        xvec_combined = torch.cat((xvec_wav, xvec_tv), dim=1)\n",
    "        \n",
    "        if self.classifier is None:\n",
    "            self.classifier = Classifier(\n",
    "                input_shape=xvec_combined.shape,\n",
    "                out_neurons=self.classifier_out_neurons,\n",
    "                lin_blocks=self.lin_blocks,\n",
    "                lin_neurons=self.lin_neurons,\n",
    "            ).to(self.device)\n",
    "        \n",
    "        logits = self.classifier(xvec_combined)\n",
    "        \n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "    # Convert each element in the batch to a tensor\n",
    "    sequences_tv = [torch.tensor(item['tv_features']) for item in batch]\n",
    "    lengths_tv = torch.tensor([len(seq) for seq in sequences_tv])  # Sequence lengths\n",
    "    \n",
    "    # Pad sequences to the same length\n",
    "    padded_sequences_tv = pad_sequence(sequences_tv, batch_first=True)\n",
    "    \n",
    "    sequences_wav = [torch.tensor(item['wav_features']) for item in batch]\n",
    "    lengths_wav = torch.tensor([len(seq) for seq in sequences_wav])  # Sequence lengths\n",
    "    \n",
    "    # Pad sequences to the same length\n",
    "    padded_sequences_wav= pad_sequence(sequences_wav, batch_first=True)\n",
    "    \n",
    "    labels = torch.tensor([item['label'] for item in batch])\n",
    "    \n",
    "    return {'sequences_wav': padded_sequences_wav, 'sequences_tv': padded_sequences_tv,'lengths_wav': lengths_wav, 'lengths_tv':lengths_tv, 'labels': labels}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_handling(fold, val_ratio=0.1, batch_size=16, norm_feat=True):\n",
    "    \n",
    "    #--Organize data in folders (similar to pcgita-split)--\n",
    "    organize_data_in_folders('train', fold)\n",
    "    organize_data_in_folders('test', fold)\n",
    "\n",
    "    #--Obtain data from csv-files--\n",
    "    csv_path_train = f\"/home/stinasb/SSL4PR/TV_train_test/Fold{fold}/train/train.csv\"\n",
    "    df_train = pd.read_csv(csv_path_train)\n",
    "\n",
    "    csv_path_test = f\"/home/stinasb/SSL4PR/TV_train_test/Fold{fold}/test/test.csv\"\n",
    "    df_test = pd.read_csv(csv_path_test)\n",
    "    \n",
    "    #--Organize data in samples, speaker_id and labels--\n",
    "    pickle_train = df_train['sample_tv']\n",
    "    pickle_test = df_test['sample_tv']\n",
    "    speaker_ids = df_train['speaker_id']\n",
    "\n",
    "    labels_train = df_train['labels']\n",
    "    labels_test = df_test['labels']\n",
    "        \n",
    "    wav_train = df_train['sample_wav']\n",
    "    wav_test = df_test['sample_wav']\n",
    "             \n",
    "    \n",
    "    #--Split training set into a train and validation set--\n",
    "    train_speaker_ids, val_speaker_ids = val_split_speaker_ids(speaker_ids, val_ratio)\n",
    "    \n",
    "    train_data, train_labels, val_data, val_labels = split_dataset(pickle_train, labels_train, train_speaker_ids, speaker_ids)\n",
    "    train_data_wav, train_labels_wav, val_data_wav, val_labels_wav = split_dataset(wav_train, labels_train, train_speaker_ids, speaker_ids)\n",
    "    \n",
    "    \n",
    "    #--Organize in CustomDataset objects--\n",
    "    train_ds = CustomDataset(train_data, is_tv=True, labels= train_labels, is_test=False, norm_feat=norm_feat)\n",
    "    val_ds = CustomDataset(val_data, is_tv=True, labels= val_labels, is_test=False, norm_feat=norm_feat)\n",
    "    test_ds = CustomDataset(pickle_test, is_tv=True, labels=labels_test, is_test=True, norm_feat=norm_feat)\n",
    "    \n",
    "    train_ds_wav = CustomDataset(train_data_wav, is_tv=False, labels= train_labels_wav, is_test=False, norm_feat=norm_feat)\n",
    "    val_ds_wav = CustomDataset(val_data_wav, is_tv=False, labels= val_labels_wav, is_test=False, norm_feat=norm_feat)\n",
    "    test_ds_wav = CustomDataset(wav_test, is_tv=False, labels=labels_test, is_test=True, norm_feat=norm_feat)\n",
    "    \n",
    "   \n",
    "    \n",
    "    \n",
    "    ds_train = WavTVDataset(train_ds_wav, train_ds)\n",
    "    ds_val = WavTVDataset(val_ds_wav, val_ds)\n",
    "    ds_test = WavTVDataset(test_ds_wav, test_ds)\n",
    "    \n",
    "    #--Load Datasets into Dataloaders--  \n",
    "    train_dl = DataLoader(ds_train, batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=True , drop_last=True)#, shuffle=True, drop_last=False)\n",
    "    val_dl = DataLoader(ds_val, batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=False)\n",
    "    test_dl = DataLoader(ds_test, batch_size=batch_size, collate_fn=custom_collate_fn, shuffle=False)\n",
    "    \n",
    "  \n",
    "    \n",
    "    return train_dl, val_dl, test_dl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_dataloader, optimizer, scheduler, device, loss_fn, multiple_models=True, gradient_accumulation_steps=1, global_step=0, is_binary_classification=False):\n",
    "    # Define a loss function and optimizer\n",
    "    \n",
    "    model.train()\n",
    "    training_loss = 0.0\n",
    "    \n",
    "    p_bar = tqdm(train_dataloader, total=len(train_dataloader), ncols=100)\n",
    "    \n",
    "    for batch in p_bar:  # Assuming your dataloader provides (inputs, labels)\n",
    "        \n",
    "        if multiple_models:\n",
    "            inputs_tv = batch['sequences_tv']\n",
    "            inputs_wav = batch['sequences_wav']\n",
    "            labels = batch['labels']\n",
    "            inputs_tv, inputs_wav, labels = inputs_tv.to(device), inputs_wav.to(device), labels.to(device)\n",
    "            lens_tv = batch['lengths_tv'].to(device)\n",
    "            lens_wav = batch['lengths_wav'].to(device)\n",
    "            \n",
    "          \n",
    "        # Forward pass\n",
    "            outputs = model(inputs_wav, inputs_tv, lens_wav, lens_tv)\n",
    "            \n",
    "        else: \n",
    "            inputs_tv = batch['sequences_tv']\n",
    "            labels = batch['labels']\n",
    "            lens_tv = batch['lengths_tv']\n",
    "            inputs_tv, labels, lens_tv = inputs_tv.to(device), labels.to(device), lens_tv.to(device)\n",
    "            outputs = model(inputs_tv, lens_tv)\n",
    "            \n",
    "        \n",
    "        \n",
    "        if torch.isnan(outputs).any():\n",
    "            print(\"Skipping batch because of nan\")\n",
    "            # clear memory\n",
    "            del batch\n",
    "            del labels\n",
    "            del outputs\n",
    "            torch.cuda.empty_cache()\n",
    "            continue\n",
    "        \n",
    "        n_classes = 2\n",
    "        \n",
    "        if is_binary_classification: loss = loss_fn(outputs.squeeze(-1), labels) #loss_fn(outputs.squeeze(-1), labels.float())\n",
    "        else: loss = loss_fn(outputs.view(-1,n_classes), labels.view(-1))\n",
    "\n",
    "        if gradient_accumulation_steps > 1:\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "            \n",
    "        loss.backward()\n",
    "        \n",
    "        if (p_bar.n + 1) % gradient_accumulation_steps == 0 or p_bar.n == len(train_dataloader) - 1:\n",
    "            optimizer.step()\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "       \n",
    "        training_loss += loss.item()\n",
    "        \n",
    "        p_bar.set_postfix({\"loss\": loss.item(), \"lr\":scheduler.get_last_lr()[-1]})\n",
    "        \n",
    "        global_step += 1\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return training_loss / len(train_dataloader), global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, eval_dataloader, device, loss_fn, multiple_models=True, is_binary_classification=False):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    p_bar = tqdm(eval_dataloader, total=len(eval_dataloader), ncols=100)\n",
    "    eval_loss = 0.0\n",
    "    reference, predictions = [], []\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in p_bar:  # Assuming (inputs, labels, lengths) from the dataloader\n",
    "            if multiple_models:\n",
    "                inputs_tv = batch['sequences_tv']\n",
    "                inputs_wav = batch['sequences_wav']\n",
    "                labels = batch['labels']\n",
    "                lens_tv = batch['lengths_tv']\n",
    "                lens_wav = batch['lengths_wav']\n",
    "                \n",
    "                inputs_tv, lens_tv, labels = inputs_tv.to(device), lens_tv.to(device), labels.to(device)\n",
    "                inputs_wav, lens_wav = inputs_wav.to(device), lens_wav.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(inputs_wav, inputs_tv, lens_wav, lens_tv)\n",
    "            else: \n",
    "                inputs_tv = batch['sequences_tv']\n",
    "                labels = batch['labels']\n",
    "                lens_tv = batch['lengths_tv']\n",
    "                \n",
    "                inputs_tv, lens_tv, labels = inputs_tv.to(device), lens_tv.to(device), labels.to(device)\n",
    "                \n",
    "                outputs = model(inputs_tv, lens_tv)\n",
    "            \n",
    "            n_classes = outputs.shape[-1]\n",
    "            \n",
    "            if is_binary_classification: loss = loss_fn(outputs.squeeze(-1), labels)\n",
    "            else: loss = loss_fn(outputs.view(-1, n_classes), labels.view(-1))\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "            reference.extend(labels.cpu().numpy())\n",
    "            if is_binary_classification: predictions.extend((outputs > 0.5).cpu().numpy().astype(int))\n",
    "            else: predictions.extend(torch.argmax(outputs, dim=-1).cpu().numpy().astype(int))\n",
    "            \n",
    "            p_bar.set_postfix({\"loss\": loss.item()})\n",
    "    return eval_loss / len(eval_dataloader), reference, predictions\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(reference, predictions, verbose=False, is_binary_classification=False):\n",
    "    accuracy = accuracy_score(reference, predictions)\n",
    "    \n",
    "    report = classification_report(reference, predictions, output_dict=True)\n",
    "    \n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 182/182 [00:35<00:00,  5.19it/s, loss=0.0796, lr=0.000256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "Average training loss: 0.0870332637658486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 21/21 [00:04<00:00,  4.95it/s, loss=0.63]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss: 0.7751839657624563\n",
      "Validation accuracy: 0.49382716049382713\n",
      "Found a better model with accuracy: 0.494 - previous best: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 182/182 [00:38<00:00,  4.69it/s, loss=0.0747, lr=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364\n",
      "Average training loss: 0.0806516474624584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 21/21 [00:02<00:00,  7.54it/s, loss=0.351]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss: 0.7306257897899264\n",
      "Validation accuracy: 0.5679012345679012\n",
      "Found a better model with accuracy: 0.568 - previous best: 0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 23/23 [00:03<00:00,  7.45it/s, loss=0.627]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy (testfold 1): 0.5388888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 182/182 [00:47<00:00,  3.86it/s, loss=0.115, lr=0.000256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "Average training loss: 0.09152173130148715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 21/21 [00:04<00:00,  4.82it/s, loss=0.323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss: 0.6697452196053096\n",
      "Validation accuracy: 0.6234567901234568\n",
      "Found a better model with accuracy: 0.623 - previous best: 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 182/182 [00:47<00:00,  3.84it/s, loss=0.0683, lr=0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364\n",
      "Average training loss: 0.08301831122774345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 21/21 [00:03<00:00,  5.30it/s, loss=0.379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average validation loss: 0.6043155633267903\n",
      "Validation accuracy: 0.7222222222222222\n",
      "Found a better model with accuracy: 0.722 - previous best: 0.623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████| 23/23 [00:04<00:00,  4.92it/s, loss=0.589]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy (testfold 2): 0.6222222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "folds = 10\n",
    "val_ratio = 0.1\n",
    "batch_size = 8\n",
    "norm_feat = True\n",
    "use_stat_pool = False\n",
    "acc_per_test_fold = {}\n",
    "\n",
    "checkpoint_path = f\"/home/stinasb/SSL4PR/checkpoints/tv_testing\"\n",
    "\n",
    "for test_fold in range(1, folds+1):\n",
    "    \n",
    "    input_size = 9\n",
    "    device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "   \n",
    "    train_dl, val_dl, test_dl = data_handling(test_fold, val_ratio=val_ratio, batch_size=batch_size, norm_feat=norm_feat)\n",
    "\n",
    "    #print(torch.cuda.memory_allocated())\n",
    "    #print(torch.cuda.memory_reserved())\n",
    "    # Combine them into a single model\n",
    "    wav_xvec = CustomXvector(input_size=80, device=device, use_stat_pool=use_stat_pool)\n",
    "    tv_xvec = CustomXvector(input_size=9, device=device, use_stat_pool=use_stat_pool)\n",
    "   \n",
    "    \n",
    "    \n",
    "    #model = CombinedModel(input_size=input_size, lin_neurons=512, xvec=tv_xvec,lin_blocks=1, classifier_out_neurons=2, device=device)\n",
    "    model = WavTVCombinedModel(wav_xvec, tv_xvec, mlp_hidden=1024, num_classes=2, device=device, lin_blocks=1)\n",
    "\n",
    "    \n",
    "    \n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.01)\n",
    "    num_epochs = 14\n",
    "    gradient_accumulation_step = 8\n",
    "\n",
    "    total_steps = int(len(train_dl)*num_epochs) // gradient_accumulation_step\n",
    "    warmup_ratio = 0.1\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=int(total_steps*warmup_ratio),\n",
    "        num_training_steps=total_steps,\n",
    "        last_epoch=-1,\n",
    "    )\n",
    "\n",
    "    is_binary_classification = False\n",
    "    multiple_models = True\n",
    "\n",
    "    if is_binary_classification: loss_fn = nn.BCELoss()\n",
    "    else: loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    global_step = 0\n",
    "    best_val_accuracy = 0\n",
    "    \n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        training_loss, global_step = train_one_epoch(\n",
    "            model=model,\n",
    "            train_dataloader=train_dl,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            device=device,\n",
    "            loss_fn=loss_fn,\n",
    "            multiple_models=multiple_models,\n",
    "            gradient_accumulation_steps=gradient_accumulation_step,\n",
    "            global_step=global_step,\n",
    "            is_binary_classification=is_binary_classification,\n",
    "        )\n",
    "        \n",
    "        print(global_step)\n",
    "        \n",
    "        print(f\"Average training loss: {training_loss}\")\n",
    "        \n",
    "        val_loss, val_reference, val_predictions = evaluate_model(\n",
    "            model=model,\n",
    "            eval_dataloader=val_dl,\n",
    "            device=device,\n",
    "            loss_fn=loss_fn,\n",
    "            multiple_models=multiple_models,\n",
    "            is_binary_classification=is_binary_classification,\n",
    "        )\n",
    "        print(f\"Average validation loss: {val_loss}\")\n",
    "\n",
    "        val_acc, val_report = compute_metrics(val_reference, val_predictions)\n",
    "        print(f\"Validation accuracy: {val_acc}\")\n",
    "        \n",
    "        if val_acc > best_val_accuracy:\n",
    "            print(f\"Found a better model with accuracy: {val_acc:.3f} - previous best: {best_val_accuracy:.3f}\")\n",
    "            best_val_accuracy = val_acc\n",
    "            torch.save(model.state_dict(), checkpoint_path + f\"/fold_{test_fold}.pt\")\n",
    "        \n",
    "        \n",
    "    model.load_state_dict(torch.load(checkpoint_path + f\"/fold_{test_fold}.pt\", weights_only=True))\n",
    " \n",
    "    test_loss, test_reference, test_predictions = evaluate_model(\n",
    "        model, test_dl, device=device, loss_fn=loss_fn, multiple_models=multiple_models)\n",
    "    \n",
    "    test_acc, test_report = compute_metrics(test_reference, test_predictions)\n",
    "    #print(f\"Testing accuracy: {test_acc}\")\n",
    "    print(f\"Testing accuracy (testfold {test_fold}): {test_acc}\")\n",
    "    acc_per_test_fold[test_fold] = test_acc\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "results_df = pd.DataFrame(acc_per_test_fold, index=[0])\n",
    "    \n",
    "results_df.to_csv(\"/home/stinasb/SSL4PR/TVs_copy\" + \"/test_results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>0.588889</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>0.692737</td>\n",
       "      <td>0.672222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          1     2         3    4         5         6         7         8  \\\n",
       "0  0.633333  0.75  0.805556  0.7  0.583333  0.811111  0.588889  0.677778   \n",
       "\n",
       "          9        10  \n",
       "0  0.692737  0.672222  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/home/stinasb/SSL4PR/TVs_copy/test_results.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 0.691495965238982\n",
      "std: 0.07548766775842185\n"
     ]
    }
   ],
   "source": [
    "print(f\"mean: {np.mean(df.values)}\")\n",
    "print(f\"std: {np.std(df.values)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/stinasb/SSL4PR/TV_train_test/Fold1/train/train.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path)\n\u001b[1;32m      5\u001b[0m df[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "path = \"/home/stinasb/SSL4PR/TV_train_test/Fold1/train/train.csv\"\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
